{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**cluster_2way**\n",
        "\n",
        "Run hierarchical models on iEEG timeseries data with one within-channel fixed effect (2 levels) and one between-channel fixed effect (2 levels), with the random effects of subject and channel nested in subject. Perform cluster-based corrections for multiple comparisons across timepoints, preserving the random effects structure. The outputs are F-statistics with uncorrected and cluster-corrected p-values.  \n",
        "\n",
        "Copyright (c) 2025  \n",
        "EL Johnson, PhD"
      ],
      "metadata": {
        "id": "aa8Vsa5-E0TK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import modules:"
      ],
      "metadata": {
        "id": "AMltVgvFbA7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.formula.api import mixedlm\n",
        "import warnings\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "\n",
        "# custom modules\n",
        "from cluster_utils import load_ieeg_data, create_df, cluster_test"
      ],
      "metadata": {
        "id": "U-BeM-TBF0Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download sample data file:\n",
        "\n",
        "Contains the following variables:  \n",
        "- sid = subject ID\n",
        "- ch = channel label\n",
        "- hit_miss = hit (1) or miss (0) within-channel variable\n",
        "- region = brain region (phrc or hc) between-channel variable\n",
        "- data = timeseries data with one row per channel per level for the within-channel variable (338 rows x 139 timepoints)"
      ],
      "metadata": {
        "id": "1URBTCtdbiNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download data from Google Drive\n",
        "output_path = 'lme_data_2way.mat'\n",
        "fid = '1AYk6KAdVkZbDSJkTKwI4XJCmdEofD9rV'\n",
        "url = f'https://drive.google.com/uc?id={fid}'\n",
        "gdown.download(url, output_path, quiet = False)\n",
        "data_path = Path(output_path)\n",
        "\n",
        "# load data\n",
        "data_dict = load_ieeg_data(data_path)\n",
        "\n",
        "# create df\n",
        "df = create_df(data_dict)\n",
        "\n",
        "print(f'\\nDataFrame: {df.shape[0]} rows Ã— {df.shape[1]} columns')\n",
        "print('\\nFirst few rows:')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "yxo9iHmXeDgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define function to run the models:"
      ],
      "metadata": {
        "id": "xxXuois_nMz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lme_2way(df, verbose = True):\n",
        "  \"\"\"\n",
        "  Run LME models across all timepoints.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pd.DataFrame\n",
        "    DataFrame from create_df()\n",
        "  verbose : bool, optional\n",
        "    If True, print progress for each timepoint. Default is True\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  dict\n",
        "    Dictionary with F-statistics and p-values for each effect:\n",
        "    - 'hit_miss': {'F': array, 'p': array}\n",
        "    - 'region': {'F': array, 'p': array}\n",
        "    - 'int': {'F': array, 'p': array}\n",
        "  \"\"\"\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  # initialize dictionary for storing model outputs\n",
        "  n_time = df.shape[1] - 4  # exclude metadata columns\n",
        "\n",
        "  lme = {\n",
        "    'hit_miss': {\n",
        "        'F': np.full(n_time, np.nan),\n",
        "        'p': np.full(n_time, np.nan)\n",
        "        },\n",
        "    'region': {\n",
        "        'F': np.full(n_time, np.nan),\n",
        "        'p': np.full(n_time, np.nan)\n",
        "        },\n",
        "    'int': {\n",
        "        'F': np.full(n_time, np.nan),\n",
        "        'p': np.full(n_time, np.nan)\n",
        "        }\n",
        "  }\n",
        "\n",
        "  # get timepoint column names\n",
        "  time_cols = [col for col in df.columns if col.startswith('t')]\n",
        "\n",
        "  # loop through timepoints\n",
        "  for t in range(n_time):\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Running model on datapoint {t+1}/{n_time}...')\n",
        "\n",
        "    # create table for model\n",
        "    tmp_dat = df[['sid', 'channel', 'hit_miss', 'region', time_cols[t]]].copy()\n",
        "    tmp_dat.rename(columns = {time_cols[t]: 'data'}, inplace = True)\n",
        "\n",
        "    # create sid:channel variable for nested random effect\n",
        "    tmp_dat['sid_ch'] = tmp_dat['sid'].astype(str) + ':' + tmp_dat['channel'].astype(str)\n",
        "\n",
        "    # run model: data ~ hit_miss * region + (1|sid) + (1|sid:channel)\n",
        "    model = mixedlm(\n",
        "        formula = 'data ~ hit_miss * region',\n",
        "        data = tmp_dat,\n",
        "        groups = tmp_dat['sid'],\n",
        "        re_formula = '1',\n",
        "        vc_formula = {'sid_ch': '0 + C(sid_ch)'}\n",
        "        )\n",
        "    result = model.fit(method = 'lbfgs', reml = True)\n",
        "\n",
        "    # get ANOVA table with F-stats\n",
        "    params = result.params\n",
        "    cov = result.cov_params()\n",
        "\n",
        "    # create contrast matrices for each effect (excluding intercept)\n",
        "    hit_miss = np.zeros((1, len(params)))\n",
        "    hit_miss[0, 1] = 1\n",
        "    region = np.zeros((1, len(params)))\n",
        "    region[0, 2] = 1\n",
        "    interact = np.zeros((1, len(params)))\n",
        "    interact[0, 3] = 1\n",
        "\n",
        "    # run F-tests\n",
        "    f_hit_miss = result.f_test(hit_miss)\n",
        "    f_region = result.f_test(region)\n",
        "    f_int = result.f_test(interact)\n",
        "\n",
        "    # extract model outputs\n",
        "    lme['hit_miss']['F'][t] = f_hit_miss.fvalue\n",
        "    lme['hit_miss']['p'][t] = f_hit_miss.pvalue\n",
        "    lme['region']['F'][t] = f_region.fvalue\n",
        "    lme['region']['p'][t] = f_region.pvalue\n",
        "    lme['int']['F'][t] = f_int.fvalue\n",
        "    lme['int']['p'][t] = f_int.pvalue\n",
        "\n",
        "  return lme"
      ],
      "metadata": {
        "id": "UCzgpsEc5GxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run model per timepoint on observed data:"
      ],
      "metadata": {
        "id": "Vi5B5rbgmFLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lme = run_lme_2way(df)"
      ],
      "metadata": {
        "id": "EFmw5v7si6hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define function to create null distributions for cluster testing:"
      ],
      "metadata": {
        "id": "zzNc5NxkAIRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_null_dist_2way(df, lme, nperm = 1000):\n",
        "  \"\"\"\n",
        "  Create null distributions for cluster testing via permutation with region effects.\n",
        "\n",
        "  Lower nperm for prototyping (multiple of 10). HPC recommended for implementation.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pd.DataFrame\n",
        "    DataFrame from create_df() containing EEG data with columns:\n",
        "    'sid', 'channel', 'hit_miss', 'region', and timepoint columns starting with 't'\n",
        "  lme : dict\n",
        "    Dictionary from run_lme_models() with 'hit_miss', 'region', and 'int'\n",
        "    subdictionaries, each containing 'F' arrays\n",
        "  nperm : int, optional\n",
        "    Number of permutations. Default is 1000\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  tuple of (array, array, array, array, array, array)\n",
        "    Returns six arrays:\n",
        "    - hit_miss_main: observed hit_miss F-statistics\n",
        "    - region_main: observed region F-statistics\n",
        "    - int_effect: observed interaction F-statistics\n",
        "    - hit_miss_main_null: null distribution for hit_miss (n_timepoints, nperm)\n",
        "    - region_main_null: null distribution for region (n_timepoints, nperm)\n",
        "    - int_null: null distribution for interaction (n_timepoints, nperm)\n",
        "  \"\"\"\n",
        "\n",
        "  # get model stats from observed data\n",
        "  hit_miss_main = lme['hit_miss']['F']\n",
        "  region_main = lme['region']['F']\n",
        "  int_effect = lme['int']['F']\n",
        "\n",
        "  # create channel-nested-in-subject IDs\n",
        "  sid_ch = df['sid'].astype(str) + ':' + df['channel'].astype(str)\n",
        "  uid = sid_ch.unique()  # unique IDs\n",
        "\n",
        "  # get region labels\n",
        "  regions = df['region'].unique()\n",
        "\n",
        "  # initialize null distributions\n",
        "  hit_miss_main_null = np.zeros((len(hit_miss_main), nperm))\n",
        "  region_main_null = np.zeros((len(region_main), nperm))\n",
        "  int_null = np.zeros((len(int_effect), nperm))\n",
        "\n",
        "  # loop through permutations\n",
        "  for p in range(nperm):\n",
        "    print(f'Shuffling the data for permutation {p+1}/{nperm}...')\n",
        "\n",
        "    # initialize shuffled labels\n",
        "    hit_miss_shuff = np.zeros(len(df), dtype = int)\n",
        "    region_shuff = np.empty(len(df), dtype = object)\n",
        "\n",
        "    # calculate region proportions\n",
        "    n_region1 = np.sum(df['region'] == regions[0]) / len(df['hit_miss'].unique())\n",
        "    n_region2 = np.sum(df['region'] == regions[1]) / len(df['hit_miss'].unique())\n",
        "\n",
        "    # loop through unique IDs\n",
        "    for u in range(len(uid)):\n",
        "      u_idx = np.where(sid_ch == uid[u])[0]\n",
        "\n",
        "      # randomly shuffle within-channel variable labels\n",
        "      if np.random.rand() > 0.5:  # coin flip\n",
        "        hit_miss_shuff[u_idx[0]] = 1  # set 1st row of pair to condition 1 (hit)\n",
        "      else:\n",
        "        hit_miss_shuff[u_idx[1]] = 1  # set 2nd row of pair to condition 1 (hit)\n",
        "\n",
        "      # randomly shuffle between-channel variable labels\n",
        "      if np.random.rand() > (n_region1 / (n_region1 + n_region2)):\n",
        "        region_shuff[u_idx[0]] = regions[0]  # set both rows to region 1\n",
        "        region_shuff[u_idx[1]] = regions[0]\n",
        "        n_region2 = n_region2 - 1\n",
        "      else:\n",
        "        region_shuff[u_idx[0]] = regions[1]  # set both rows to region 2\n",
        "        region_shuff[u_idx[1]] = regions[1]\n",
        "        n_region1 = n_region1 - 1\n",
        "\n",
        "    # create shuffled df\n",
        "    df_shuff = df.copy()\n",
        "    df_shuff['hit_miss'] = hit_miss_shuff.astype(bool)  # convert to boolean\n",
        "    df_shuff['region'] = region_shuff\n",
        "\n",
        "    # run model per timepoint with shuffled labels\n",
        "    lme_null = run_lme_2way(df_shuff, verbose=False)\n",
        "\n",
        "    # extract model outputs\n",
        "    hit_miss_main_null[:, p] = lme_null['hit_miss']['F']\n",
        "    region_main_null[:, p] = lme_null['region']['F']\n",
        "    int_null[:, p] = lme_null['int']['F']\n",
        "\n",
        "  return hit_miss_main, region_main, int_effect, hit_miss_main_null, region_main_null, int_null"
      ],
      "metadata": {
        "id": "RkdFfXTVAJzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create null distributions for cluster testing:"
      ],
      "metadata": {
        "id": "m8dlzVqT7Zs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hit_miss_main, region_main, int_effect, hit_miss_main_null, region_main_null, int_null = \\\n",
        "  create_null_dist_2way(df, lme, nperm = 10)  # lowered nperm for demo"
      ],
      "metadata": {
        "id": "Q5fZWGObBUc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run cluster tests:"
      ],
      "metadata": {
        "id": "0ne95lF0RPl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main effect of within-channel variable (hit/miss)\n",
        "_, p, _ = cluster_test(hit_miss_main, hit_miss_main_null, tail = 1)\n",
        "lme['hit_miss']['p_clust'] = p.flatten()\n",
        "\n",
        "# main effect of between-channel variable (region)\n",
        "_, p, _ = cluster_test(region_main, region_main_null, tail = 1)\n",
        "lme['region']['p_clust'] = p.flatten()\n",
        "\n",
        "# interaction (hit/miss*region)\n",
        "_, p, _ = cluster_test(int_effect, int_null, tail = 1)\n",
        "lme['int']['p_clust'] = p.flatten()"
      ],
      "metadata": {
        "id": "B4KCJSDwTEdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save:"
      ],
      "metadata": {
        "id": "BLJzlfZ2TNiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lme_clust_2way.pkl', 'wb') as f:\n",
        "  pickle.dump(lme, f)"
      ],
      "metadata": {
        "id": "_iDBRprLTOjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load from Colab Files panel:  \n",
        "```\n",
        "with open('lme_clust_2way.pkl', 'rb') as f:  \n",
        "  lme = pickle.load(f)\n",
        "```\n",
        "\n",
        "To download from Colab:  \n",
        "```\n",
        "from google.colab import files  \n",
        "files.download('lme_clust_2way.pkl')\n",
        "```"
      ],
      "metadata": {
        "id": "HE0CAQlJZMv-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hkM4JdwapNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}