{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**cluster_1way**\n",
        "\n",
        "Run hierarchical models on iEEG timeseries data with one within-channel fixed effect (2 levels), with the random effects of subject and channel nested in subject. Perform cluster-based corrections for multiple comparisons across timepoints, preserving the random effects structure. The outputs are two-tailed t-statistics with uncorrected and cluster-corrected p-values.\n",
        "\n",
        "Copyright (c) 2025  \n",
        "EL Johnson, PhD"
      ],
      "metadata": {
        "id": "aa8Vsa5-E0TK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import modules:"
      ],
      "metadata": {
        "id": "AMltVgvFbA7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.formula.api import mixedlm\n",
        "import warnings\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "\n",
        "# custom modules\n",
        "from cluster_utils import load_ieeg_data, create_df, cluster_test"
      ],
      "metadata": {
        "id": "U-BeM-TBF0Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download sample data file:\n",
        "\n",
        "Contains the following variables:  \n",
        "- sid = subject ID\n",
        "- ch = channel label\n",
        "- hit_miss = hit (1) or miss (0) within-channel variable\n",
        "- data = timeseries data with one row per channel per level for the within-channel variable (186 rows x 139 timepoints)"
      ],
      "metadata": {
        "id": "1URBTCtdbiNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download data from Google Drive\n",
        "output_path = 'lme_data_1way.mat'\n",
        "fid = '1i170RbUZuRQzY8gzEC99XBdo4uyCbsl4'\n",
        "url = f'https://drive.google.com/uc?id={fid}'\n",
        "gdown.download(url, output_path, quiet = False)\n",
        "data_path = Path(output_path)\n",
        "\n",
        "# load data\n",
        "data_dict = load_ieeg_data(data_path)\n",
        "\n",
        "# create df\n",
        "df = create_df(data_dict)\n",
        "\n",
        "print(f'\\nDataFrame: {df.shape[0]} rows Ã— {df.shape[1]} columns')\n",
        "print('\\nFirst few rows:')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "yxo9iHmXeDgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define function to run the models:"
      ],
      "metadata": {
        "id": "ywziXROElCk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lme_1way(df, verbose = True):\n",
        "  \"\"\"\n",
        "  Run LME models across all timepoints.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pd.DataFrame\n",
        "    DataFrame from create_df()\n",
        "  verbose : bool, optional\n",
        "    If True, print progress for each timepoint. Default is True\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  dict\n",
        "    Dictionary with t-statistic and p-value:\n",
        "    - 't': array\n",
        "    - 'p': array\n",
        "  \"\"\"\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  # initialize dictionary for storing model outputs\n",
        "  n_time = df.shape[1] - 4  # exclude metadata columns\n",
        "\n",
        "  lme = {\n",
        "    't': np.full(n_time, np.nan),\n",
        "    'p': np.full(n_time, np.nan)\n",
        "  }\n",
        "\n",
        "  # get timepoint column names\n",
        "  time_cols = [col for col in df.columns if col.startswith('t')]\n",
        "\n",
        "  # loop through timepoints\n",
        "  for t in range(n_time):\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Running model on datapoint {t+1}/{n_time}...')\n",
        "\n",
        "    # create table for model\n",
        "    tmp_dat = df[['sid', 'channel', 'hit_miss', time_cols[t]]].copy()\n",
        "    tmp_dat.rename(columns = {time_cols[t]: 'data'}, inplace = True)\n",
        "\n",
        "    # create sid:channel variable for nested random effect\n",
        "    tmp_dat['sid_ch'] = tmp_dat['sid'].astype(str) + ':' + tmp_dat['channel'].astype(str)\n",
        "\n",
        "    # run model: data ~ hit_miss + (1|sid) + (1|sid:channel)\n",
        "    model = mixedlm(\n",
        "        formula = 'data ~ hit_miss',\n",
        "        data = tmp_dat,\n",
        "        groups = tmp_dat['sid'],\n",
        "        re_formula = '1',\n",
        "        vc_formula = {'sid_ch': '0 + C(sid_ch)'}\n",
        "        )\n",
        "    result = model.fit(method = 'lbfgs', reml = True)\n",
        "\n",
        "    # extract model outputs\n",
        "    lme['t'][t] = result.tvalues[1]\n",
        "    lme['p'][t] = result.pvalues[1]\n",
        "\n",
        "  return lme"
      ],
      "metadata": {
        "id": "UCzgpsEc5GxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run model per timepoint on observed data:"
      ],
      "metadata": {
        "id": "xxXuois_nMz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lme = run_lme_1way(df)"
      ],
      "metadata": {
        "id": "EFmw5v7si6hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define function to create null distributions for cluster testing:"
      ],
      "metadata": {
        "id": "OpTRJl_m9oSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_null_dist_1way(df, lme, nperm = 1000):\n",
        "  \"\"\"\n",
        "  Create null distributions for cluster testing via permutation.\n",
        "\n",
        "  Lower nperm for prototyping (multiple of 10). HPC recommended for implementation.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pd.DataFrame\n",
        "    DataFrame from create_df() containing EEG data with columns:\n",
        "    'sid', 'channel', 'hit_miss', and timepoint columns starting with 't'\n",
        "  lme : dict\n",
        "    Dictionary from run_lme_models() with 't' and 'p' arrays\n",
        "  nperm : int, optional\n",
        "    Number of permutations. Default is 1000\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  tuple of (array, array)\n",
        "    Returns two arrays:\n",
        "    - hit_miss: observed hit_miss t-statistics\n",
        "    - hit_miss_null: null distribution for hit_miss (n_timepoints, nperm)\n",
        "  \"\"\"\n",
        "\n",
        "  # get model stats from observed data\n",
        "  hit_miss = lme['t']\n",
        "\n",
        "  # create channel-nested-in-subject IDs\n",
        "  sid_ch = df['sid'].astype(str) + ':' + df['channel'].astype(str)\n",
        "  uid = sid_ch.unique()  # unique IDs\n",
        "\n",
        "  # initialize null distributions\n",
        "  hit_miss_null = np.zeros((len(hit_miss), nperm))\n",
        "\n",
        "  # loop through permutations\n",
        "  for p in range(nperm):\n",
        "    print(f'Shuffling the data for permutation {p+1}/{nperm}...')\n",
        "\n",
        "    # initialize shuffled labels\n",
        "    hit_miss_shuff = np.zeros(len(df), dtype = int)\n",
        "\n",
        "    # loop through unique IDs\n",
        "    for u in range(len(uid)):\n",
        "      u_idx = np.where(sid_ch == uid[u])[0]\n",
        "\n",
        "      # randomly shuffle within-channel variable labels\n",
        "      if np.random.rand() > 0.5:  # coin flip\n",
        "        hit_miss_shuff[u_idx[0]] = 1  # set 1st row of pair to condition 1 (hit)\n",
        "      else:\n",
        "        hit_miss_shuff[u_idx[1]] = 1  # set 2nd row of pair to condition 1 (hit)\n",
        "\n",
        "    # create shuffled df\n",
        "    df_shuff = df.copy()\n",
        "    df_shuff['hit_miss'] = hit_miss_shuff.astype(bool)  # convert to boolean\n",
        "\n",
        "    # run model per timepoint with shuffled labels\n",
        "    lme_null = run_lme_1way(df_shuff, verbose = False)\n",
        "\n",
        "    # extract model outputs\n",
        "    hit_miss_null[:, p] = lme_null['t']\n",
        "\n",
        "  return hit_miss, hit_miss_null"
      ],
      "metadata": {
        "id": "zl9WV94M9tso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create null distributions for cluster testing:"
      ],
      "metadata": {
        "id": "m8dlzVqT7Zs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hit_miss, hit_miss_null = create_null_dist_1way(df, lme, nperm = 10)  # lowered nperm for demo"
      ],
      "metadata": {
        "id": "F_g_dmLi-ovq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run cluster test:"
      ],
      "metadata": {
        "id": "0ne95lF0RPl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, p, _ = cluster_test(hit_miss, hit_miss_null, tail = 0)\n",
        "lme['p_clust'] = p.flatten()"
      ],
      "metadata": {
        "id": "B4KCJSDwTEdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save:"
      ],
      "metadata": {
        "id": "BLJzlfZ2TNiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lme_clust_1way.pkl', 'wb') as f:\n",
        "  pickle.dump(lme, f)"
      ],
      "metadata": {
        "id": "_iDBRprLTOjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load from Colab Files panel:  \n",
        "```\n",
        "with open('lme_clust_2way.pkl', 'rb') as f:  \n",
        "  lme = pickle.load(f)\n",
        "```\n",
        "\n",
        "To download from Colab:  \n",
        "```\n",
        "from google.colab import files  \n",
        "files.download('lme_clust_2way.pkl')\n",
        "```"
      ],
      "metadata": {
        "id": "HE0CAQlJZMv-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AVVmks2J87Cl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}